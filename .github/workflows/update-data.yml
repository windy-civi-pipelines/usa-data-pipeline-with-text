name: Update Data

on:
  schedule:
    - cron: "0 1 * * *" # every day at 1am UTC
  workflow_dispatch:
    inputs:
      use-scrape-cache:
        type: boolean
        description: Use open states scraper cache
      force-update:
        type: boolean
        description: 'Force push changes even if there are upstream changes (use with caution)'

jobs:
  update-data:
    name: Update Data
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: windy-civi/opencivicdata-blockchain-transformer@bill-text-extraction
        with:
           state: usa
           github-token: ${{ secrets.GITHUB_TOKEN }}
           use-scrape-cache: ${{ inputs.use-scrape-cache }}
           force-update: ${{ inputs.force-update }}
      
      # Add this step to upload the processed data
      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data_output/data_processed
          retention-days: 1

  extract-bill-text:
    name: Extract Bill Text
    runs-on: ubuntu-latest
    needs: update-data
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          repository: windy-civi/opencivicdata-blockchain-transformer
          ref: bill-text-extraction
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      # Add this step to download the processed data
      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data_output/data_processed
      
      - name: Extract Bill Text
        run: |
          python openstates_scraped_data_formatter/extract_bill_text.py \
            --processed-folder ./data_output/data_processed \
            --batch-size 100
